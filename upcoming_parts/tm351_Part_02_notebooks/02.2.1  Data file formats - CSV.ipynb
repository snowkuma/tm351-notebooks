{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV files are one of the most commonly used file formats for sharing data.\n",
    "\n",
    "In the `data` folder there is a subfolder called `iwCouncilSpending` that contains several CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Unix commands to examine CSV file content\n",
    "\n",
    "The `ls` command will list the contents of a folder, showing the CSV files and the file sizes in bytes (the number before the file date)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "!ls -l data/iwCouncilSpending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file size tells you how large the file is and gives you a clue as to how many lines of data are in the file.\n",
    "\n",
    "One of the easiest ways of previewing a CSV file is from the command line using the `head` command. By default this previews the first 10 lines of the file. If the name of the file you want to preview contains spaces, you can either escape them using a backslash, or put the whole filepath and filename into a string:\n",
    "\n",
    "* `!head data/iwCouncilSpending/PUBLISHED FORMAT\\ -\\ NOV\\ 2013.csv`\n",
    "* `!head 'data/iwCouncilSpending/PUBLISHED FORMAT - NOV 2013.csv'`\n",
    "   \n",
    "The `-n` switch can be used to change the number of lines shown. \n",
    "\n",
    "For example, the following command previews the first 5 lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "!head -n 5 'data/iwCouncilSpending/PUBLISHED FORMAT - NOV 2013.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can count the number of lines in the file using the `wc` command with the `-l` switch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "!wc -l 'data/iwCouncilSpending/PUBLISHED FORMAT - NOV 2013.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first number output is the number of lines, followed by the filename. How many lines are in the file you selected?\n",
    "\n",
    "Remember, in a CSV file a data *row* may actually be split over several lines. This means that the line count is an upper bound on the number of rows of data that may be in the file.\n",
    "\n",
    "It always makes sense to get a feel for the size of a file before you try to open it. The `head` command is a safe way of previewing the first few lines of the file. The `tail` command, conversely, allows you to preview the last few lines of the file. This can be useful if you want to know whether the file contains a blank line at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "!tail -n 5 'data/iwCouncilSpending/PUBLISHED FORMAT - NOV 2013.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to read in the CSV file a line at a time, we are likely to run into complications if the value of a cell contains a line break that splits a single data *row* over several *file* lines, so we would benefit from using a library for CSV file handling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV and _pandas_\n",
    "\n",
    "The _pandas_ library provides a set of utilities for reading (and writing) CSV files that can cope with issues such as data rows split over more than one file line. The _pandas_ library also contains routines for working with CSV data, and it is these that we shall be using throughout the module.    (The library also provides a function that can read CSV files into a *dict* using the column header as dict keys.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `data/iwCouncilSpending/` directory there is a small file  - `sample1.csv` - containing a sample of rows (including a header row) from one of the spending data files. We can import that data into pandas in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv('data/iwCouncilSpending/sample1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": "activity"
   },
   "source": [
    "### Exercise\n",
    "The same directory also contains a file `sample2.csv`. In this exercise use the cells below to first preview the file and then load it in using the _pandas_ `read_csv()` function. What happens this time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": "activity",
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Preview the sample2.csv file using the command line. \n",
    "#    What else can you learn about it from the command line?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": "activity"
   },
   "source": [
    "<div style=\"color:blue\">*Your observations ...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": "activity",
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Use the pandas read_csv() function to load in sample2.csv. What happens?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": "activity"
   },
   "source": [
    "<div style=\"color:blue\">*Your observations...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to the pandas CSV \n",
    "If you have a large file, you may not want to load it into memory all at once. Instead, you might want to load the data in a row at a time, or a chunk of rows at a time. The `nrows` parameter allows you to define how many rows you want to load in from the start of the file, in much the same way as the command-line `head` command does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv('data/iwCouncilSpending/sample1.csv', nrows=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you might want to load in the whole file, but handle the rows in chunks. The `chunksize` parameter allows you to read data in from a file *chunksize* rows at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "chunks = pd.read_csv('data/iwCouncilSpending/sample1.csv', chunksize=4)\n",
    "for chunk in chunks:\n",
    "    print('New chunk...')\n",
    "    print(chunk[ ['Transaction Number', 'Date', 'Amount'] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cases, you may find that the data you want to work with is available as a data file on the web. You could download such a file using a web browser, or by any other means, and then load your downloaded copy of the file into the Notebook. Or, you can load a file directly into the Notebook from a web URL using pandas' `read_csv()` function - simply use the file's URL as the filename. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "csvFromWeb = pd.read_csv('http://www.iwight.com/documentlibrary/download/november-2013-transparency-data-csv')\n",
    "csvFromWeb[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing DataFrames to CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To write the data in a DataFrame out to a CSV file, we can use the `to_csv()` function with a supplied target filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Write the data frame to the named file.\n",
    "csvFromWeb.to_csv('data/iwCouncilSpending/csvFromWeb.csv')\n",
    "# Show the first 5 lines of the newly written file.\n",
    "pd.read_csv('data/iwCouncilSpending/csvFromWeb.csv', nrows=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you examine the output you will see that by default, the index column and header row will be written out - but, both can be disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "csvFromWeb.to_csv('data/iwCouncilSpending/csvFromWeb.csv', index=False, header=False)\n",
    "pd.read_csv('data/iwCouncilSpending/csvFromWeb.csv', nrows=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ooops! `read_csv()` expects a header line, but we chose not to write one.\n",
    "\n",
    "If we know there is no header line, then we need to declare this when reading the data in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv('data/iwCouncilSpending/csvFromWeb.csv', nrows=5, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add headers to an unheaded CSV file, we can use the `names` parameter to `read_csv()`. \n",
    "\n",
    "We can get a list of the column names from the original file using `columns.values.tolist()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "origNames = csvFromWeb.columns.values.tolist()\n",
    "origNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv('data/iwCouncilSpending/csvFromWeb.csv', nrows=5, header=None, names=origNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read in just a specific set of columns, use the `usecols` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "tmp = pd.read_csv('data/iwCouncilSpending/sample1.csv', nrows=3, usecols=['Date','Transaction Number','Amount'])\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on `read_csv()`, see the *pandas* documentation: [pandas.io.parsers.read_csv](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.io.parsers.read_csv.html).\n",
    "\n",
    "For more information on `DataFrame.to_csv()`, see the *pandas* documentation for  [pandas.DataFrame.to_csv](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Typing data in columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cases a CSV file will contain columns of data that conform to a particular type, although the type may not be detected when the data is simply read in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# We need to specify the encoding of this file or it will not be opened.\n",
    "# A good guess for the filetype of a CSV file that does not open with \n",
    "#    the default settings is ISO-8859-1 or equivalently latin-1.\n",
    "\n",
    "#For some notes on how to try to find what encoding a particular file is\n",
    "#see the 02.2.0 Data file formats - file encodings Notebook.\n",
    "\n",
    "df = pd.read_csv('data/iwCouncilSpending/PUBLISHED FORMAT - NOV 2013.csv', encoding=\"ISO-8859-1\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful test to run on one or more columns is a summary review of the unique values that exist within a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "uniquevalues = df['Directorate'].unique()\n",
    "uniquevalues"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "One thing we may want to do is cast a column to a particular type - for example, we might want to cast the `Amount` column to a number of type `float`.\n",
    "\n",
    "One way of trying to do this is using the _pandas_ `to_numeric()` function to convert the values in the `Amount` column to a numeric type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# This will fail with an error message\n",
    "pd.to_numeric(df['Amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Do the same again, but this time tell the to_numeric() function \n",
    "# to ignore any errors while it attempts the conversion\n",
    "pd.to_numeric(df['Amount'], errors='ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the comma in the value `5,285.00` in the third row means this entry is seen as a string that cannot be simply converted to a number.\n",
    "\n",
    "What happens if we try a more direct route, saying we specifically want to cast the values in the column to a `float` type?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A solution to this is to get rid of the comma using a `str.replace()` function applied to each value in the column, and then use the `to_numeric()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pd.to_numeric(df['Amount'].str.replace(',',''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there is an easier way. With delimiters commonly being used to separate 'thousands' in many number strings, _pandas_ usefully provides a way of automatically handling these as the CSV file is read. Specifically, you can handle the separator automatically by setting the `thousands` parameter appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/iwCouncilSpending/PUBLISHED FORMAT - NOV 2013.csv', thousands=',',\n",
    "                  encoding=\"latin-1\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the `read_csv()` function can identify a column type unambiguously, it will do so. For example, if we just use the first few lines of the CSV file, we see how the `Amount` column values can all be cast directly to an appropriate numeric type without error and as a result the `read_csv()` function does cast the column type automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/iwCouncilSpending/PUBLISHED FORMAT - NOV 2013.csv', nrows=3)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the file loaded that time without an error, but without setting the encoding. \n",
    "Why? \n",
    "\n",
    "We only loaded in the first three lines - presumably the encoded characters that were causing the problem are not in these three lines.\n",
    "\n",
    "We can also try to force the type using the `dtype` parameter, though if an illegal cast is attempted an error will be raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/iwCouncilSpending/PUBLISHED FORMAT - NOV 2013.csv',\n",
    "                  nrows=3, dtype={'Transaction Number':float})\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One column type that appears in many datasets is dates, or dates and times, although the way in which dates are actually presented may vary widely from dataset to dataset. For example, 12/3/14, 12-Mar-2014 and 2014-03-12 all represent the same date. If we specify the name of a date column, _pandas_ `read_csv()` will try to automatically detect the corresponding date representation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/iwCouncilSpending/PUBLISHED FORMAT - NOV 2013.csv',\n",
    "                 parse_dates=['Date'], encoding=\"latin-1\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes there may be ambiguity about whether the day or month is provided first. For example is 1/2/13 the 1st of February or a US styled 2nd of January? Specifying `dayfirst=True` clearly identifies the first convention should be assumed.\n",
    "\n",
    "A date format can also be declared explicitly - to see how, check the documentation: [pandas.io.parsers.read_csv](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.io.parsers.read_csv.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this Notebook you have seen how to:\n",
    "1. use a range of Unix commands to find out what is in a file\n",
    "2. use *pandas* to read a CSV file\n",
    "3. write data in a DataFrame to a CSV file\n",
    "4. examine the datatypes and parse dates when reading a CSV file\n",
    "5. You've also been reminded where the *pandas* and Dataframe documentation can be found.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are working through this Notebook as part of an inline exercise, return to the module materials now.\n",
    "\n",
    "If you are working through this set of Notebooks as a whole, move on to look at `02.2.2 Data File Formats - JSON`. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
